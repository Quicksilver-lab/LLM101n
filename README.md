# LLM101n: Let's build a Storyteller

![LLM101n header image](llm101n.jpg)

> ‚ÄúWhat I cannot create, I do not understand.‚Äù - Richard Feynman

Welcome to **LLM101n**, where we embark on an exciting journey to build a **Storyteller AI Large Language Model (LLM)** from scratch! This course will guide you through every step of creating, refining, and illustrating captivating stories using AI. By the end of this course, you'll have a solid understanding of AI, LLMs, and deep learning concepts.

## üìö Course Highlights

We'll cover everything from the basics to a fully functional web app, including:

- **Python, C, and CUDA** programming
- Language modeling, machine learning, and deep learning
- Building and optimizing large-scale AI systems

## üìú Syllabus

### **Chapter 01: [Bigram Language Model](bigram/README.md)**  
Learn the fundamentals of language modeling with bigram models. 

### **Chapter 02: [Micrograd](micrograd/README.md)**  
Explore machine learning and backpropagation with Micrograd. 

### **Chapter 03: [N-gram Model](mlp/README.md)**  
Dive into multi-layer perceptrons, matrix multiplication, and GELU activation. 

### **Chapter 04: [Attention](attention/README.md)**  
Understand attention mechanisms, softmax, and positional encoding. 

### **Chapter 05: [Transformer](transformer/README.md)**  
Master the transformer architecture, residual connections, and layer normalization. 

### **Chapter 06: [Tokenization](tokenization/README.md)**  
Get hands-on with tokenization techniques like minBPE and byte pair encoding. 

### **Chapter 07: [Optimization](optimization/README.md)**  
Optimize your models with techniques such as initialization and AdamW. 

### **Chapter 08: [Need for Speed I: Device](device/README.md)**  
Learn about device optimization, CPU, GPU, and more. 

### **Chapter 09: [Need for Speed II: Precision](precision/README.md)**  
Explore mixed precision training with fp16, bf16, and fp8. 

### **Chapter 10: [Need for Speed III: Distributed](distributed/README.md)**  
Understand distributed optimization, DDP, and ZeRO techniques. 

### **Chapter 11: [Datasets](datasets/README.md)**  
Work with datasets, data loading, and synthetic data generation. 

### **Chapter 12: [Inference I: kv-cache](inference/README.md)**  
Optimize inference with key-value caching. 

### **Chapter 13: [Inference II: Quantization](quantization/README.md)**  
Learn about quantization techniques for efficient model deployment. 

### **Chapter 14: [Finetuning I: SFT](sft/README.md)**  
Explore supervised finetuning, PEFT, LoRA, and chat models. 

### **Chapter 15: [Finetuning II: RL](rl/README.md)**  
Delve into reinforcement learning with RLHF, PPO, and DPO. 

### **Chapter 16: [Deployment](deployment/README.md)**  
Deploy your AI models with API integration and web apps. 

### **Chapter 17: [Multimodal](multimodal/README.md)**  
Expand your knowledge with multimodal AI, including VQVAE and diffusion transformers. 

## üõ†Ô∏è Additional Topics

- **Programming Languages:** Assembly, C, Python 
- **Data Types:** Integer, Float, String (ASCII, Unicode, UTF-8) 
- **Tensor Operations:** Shapes, views, strides, contiguous 
- **Deep Learning Frameworks:** PyTorch, JAX 
- **Neural Net Architectures:** GPT (1,2,3,4), Llama (RoPE, RMSNorm, GQA), MoE 
- **Multimodal AI:** Images, Audio, Video, VQVAE, VQGAN, diffusion

## üìÖ Course Update

As of **June 25**, please note that the course is still in development and will take some time to complete. We appreciate your interest and kindly request that you refrain from submitting Issues or Pull Requests (PRs) at this time. Thank you for your understanding and patience.

---

Feel free to reach out with any questions or feedback. Happy learning! üòä

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue)](https://www.python.org/)
[![CUDA](https://img.shields.io/badge/CUDA-11.0%2B-orange)](https://developer.nvidia.com/cuda-toolkit)
[![C](https://img.shields.io/badge/C-11.0%2B-green)](https://en.wikipedia.org/wiki/C%2B%2B)
[![License](https://img.shields.io/badge/License-MIT-yellow)](LICENSE)
